{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6183216a84074985986f6e0b71b5f131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5be35566435c4c64a941ce6be3755bb3",
              "IPY_MODEL_270defb485ec455dbc69a9e829b4d9a3",
              "IPY_MODEL_55ecad4bbf234a1e8b0ef9d44c4fa0ff"
            ],
            "layout": "IPY_MODEL_00d27fc799724d02a39eb24a2a9efa13"
          }
        },
        "5be35566435c4c64a941ce6be3755bb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b462cd2fb15b45a8a602faedd2108b3e",
            "placeholder": "​",
            "style": "IPY_MODEL_fb64ae570ace4f75a51db88437bc01f0",
            "value": "100%"
          }
        },
        "270defb485ec455dbc69a9e829b4d9a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f09e00b71474878be18b8255ee62e87",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5ae9954bf0149d78dfa040571177ec3",
            "value": 100
          }
        },
        "55ecad4bbf234a1e8b0ef9d44c4fa0ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d618a1674aaa4ab093ba0d622f7f4deb",
            "placeholder": "​",
            "style": "IPY_MODEL_06dcab0e488d465fb48032885cd8d3aa",
            "value": " 100/100 [21:01&lt;00:00, 12.49s/it]"
          }
        },
        "00d27fc799724d02a39eb24a2a9efa13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b462cd2fb15b45a8a602faedd2108b3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb64ae570ace4f75a51db88437bc01f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f09e00b71474878be18b8255ee62e87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5ae9954bf0149d78dfa040571177ec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d618a1674aaa4ab093ba0d622f7f4deb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06dcab0e488d465fb48032885cd8d3aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JBlake26/ECGR4105_IntroToML/blob/main/HW6_P2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 2a**\n",
        "\n",
        "Build a Convolutional Neural Network, like what we built in lectures to classify the images across all 10 classes in CIFAR 10. You need to adjust the fully connected layer at the end properly with respect to the number of output classes. Train your network for 300 epochs. Report your training time, training loss, and evaluation accuracy after 300 epochs. Analyze your results in your report and compare them against a fully connected network (Problem 1) on training time, achieved accuracy, and model size."
      ],
      "metadata": {
        "id": "_PpKDT1nN7dg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzXxPD74UaH8"
      },
      "outputs": [],
      "source": [
        "#drive.mount('/content/drive/')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import torch\n",
        "import imageio\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import KFold \n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn import datasets\n",
        "from sklearn import metrics\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
        "from matplotlib.colors import ListedColormap\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg', 'pdf') # For export\n",
        "from matplotlib.colors import to_rgba\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "## Progress bar\n",
        "from tqdm.notebook import tqdm\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch\n",
        "import torch\n",
        "print(\"Using torch\", torch.__version__)"
      ],
      "metadata": {
        "id": "RGoY8zkQUdH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81b9327e-6a86-4557-9122-0d12865d5e34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using torch 1.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42) # Setting the seed"
      ],
      "metadata": {
        "id": "bqikC__QUfAZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf42ef91-b426-4d98-b3f7-c27c33f38d93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f10f55d09d0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_avail = torch.cuda.is_available()\n",
        "print(f\"Is the GPU available? {gpu_avail}\")"
      ],
      "metadata": {
        "id": "DaTCWyJTUkD3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52547af7-e1f5-44af-8ff4-48ddf0673f73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the GPU available? False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device\", device)"
      ],
      "metadata": {
        "id": "vxojgFOHU5G4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c2516ab-a5d8-4c1e-d7cc-fad823031ffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(5000, 5000)\n",
        "\n",
        "## CPU version\n",
        "start_time = time.time()\n",
        "_ = torch.matmul(x, x)\n",
        "end_time = time.time()\n",
        "print(f\"CPU time: {(end_time - start_time):6.5f}s\")\n",
        "\n",
        "## GPU version\n",
        "x = x.to(device)\n",
        "# CUDA is asynchronous, so we need to use different timing functions\n",
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "start.record()\n",
        "_ = torch.matmul(x, x)\n",
        "end.record()\n",
        "torch.cuda.synchronize() # Waits for everything to finish running on the GPU\n",
        "print(f\"GPU time: {0.001 * start.elapsed_time(end):6.5f}s\") # Milliseconds to seconds"
      ],
      "metadata": {
        "id": "0-28EDlSU7bV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "    torch.backends.cudnn.determinstic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "YNujJDxPVEFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils import data\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import torch.utils.data as data\n",
        "\n",
        "data_path = '../data'\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(data_path, train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(data_path, train=False, download=True, transform=transform)\n",
        "\n",
        "data_labels = ('plane', 'car', 'bird', 'cat', )\n"
      ],
      "metadata": {
        "id": "XLQAsR9tX-AH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class SimpleClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        # Initialize the modules we need to build the network\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16*5*5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Perform the calculation of the model to determine the prediction\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16*5*5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "8-5_pTZyO8Up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleClassifier2(nn.Module):\n",
        "    def __init__(self):\n",
        "        # Initialize the modules we need to build the network\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.conv2 = nn.Conv2d(6, 12, 5)\n",
        "        self.pool2 = nn.MaxPool2d(2,2)\n",
        "        self.conv3 = nn.Conv2d(12,24,5)\n",
        "        self.fc1 = nn.Linear(24*5*5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84,42)\n",
        "        self.fc4 = nn.Linear(42, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Perform the calculation of the model to determine the prediction\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 24*5*5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "PzMCQj1CO2vU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleClassifier()\n",
        "# Printing a module shows all its submodules\n",
        "print(model)\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        " print(f\"Parameter {name}, shape {param.shape}\")"
      ],
      "metadata": {
        "id": "DjuBq2KYVH11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c8a33b9-fb0d-44aa-d21a-80a7320b1be7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleClassifier(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "Parameter conv1.weight, shape torch.Size([6, 3, 5, 5])\n",
            "Parameter conv1.bias, shape torch.Size([6])\n",
            "Parameter conv2.weight, shape torch.Size([16, 6, 5, 5])\n",
            "Parameter conv2.bias, shape torch.Size([16])\n",
            "Parameter fc1.weight, shape torch.Size([120, 400])\n",
            "Parameter fc1.bias, shape torch.Size([120])\n",
            "Parameter fc2.weight, shape torch.Size([84, 120])\n",
            "Parameter fc2.bias, shape torch.Size([84])\n",
            "Parameter fc3.weight, shape torch.Size([10, 84])\n",
            "Parameter fc3.bias, shape torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = SimpleClassifier()\n",
        "print(model)\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        " print(f\"Parameter {name}, shape {param.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U58p_qjonWwx",
        "outputId": "565c643a-82ab-42c5-c059-c228f6d94216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleClassifier(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "Parameter conv1.weight, shape torch.Size([6, 3, 5, 5])\n",
            "Parameter conv1.bias, shape torch.Size([6])\n",
            "Parameter conv2.weight, shape torch.Size([16, 6, 5, 5])\n",
            "Parameter conv2.bias, shape torch.Size([16])\n",
            "Parameter fc1.weight, shape torch.Size([120, 400])\n",
            "Parameter fc1.bias, shape torch.Size([120])\n",
            "Parameter fc2.weight, shape torch.Size([84, 120])\n",
            "Parameter fc2.bias, shape torch.Size([84])\n",
            "Parameter fc3.weight, shape torch.Size([10, 84])\n",
            "Parameter fc3.bias, shape torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"data loader - Pre-processing\"\n",
        "data_loader = data.DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "# next(iter(...)) catches the first batch of the data loader\n",
        "# If shuffle is True, this will return a different batch every time we run this cell\n",
        "# For iterating over the whole dataset, we can simple use \"for batch in data_loader: ...\"\n",
        "data_inputs, data_labels = next(iter(data_loader))\n",
        "\n",
        "# The shape of the outputs are [batch_size, d_1,...,d_N], where d_1,...,d_N are the dimensions of the data points\n",
        "#print(\"Data inputs\", data_inputs.shape, \"\\n\", data_inputs)\n",
        "print(\"Data labels\", data_labels.shape, \"\\n\", data_labels)"
      ],
      "metadata": {
        "id": "0-WzY5e-loRz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9938f5d5-e958-4133-bb93-84252de69b4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data labels torch.Size([2]) \n",
            " tensor([1, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"Saving the Trained model\"\n",
        "state_dict = model.state_dict()\n",
        "print(state_dict)\n",
        "# torch.save(object, filename). For the filename, any extension can be used\n",
        "torch.save(state_dict, \"our_model.tar\")\n",
        "# Load state dict from the disk (make sure it is the same name as above)\n",
        "state_dict = torch.load(\"our_model.tar\")\n",
        "# Create a new model and load the state\n",
        "new_model = SimpleClassifier()\n",
        "new_model.load_state_dict(state_dict)\n",
        "# Verify that the parameters are the same\n",
        "print(\"Original model\\n\", model.state_dict())\n",
        "print(\"\\nLoaded model\\n\", new_model.state_dict())"
      ],
      "metadata": {
        "id": "bjzZQMg-lxGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"Evaluation Code\"\n",
        "test_dataset = test_dataset\n",
        "# drop_last -> Don't drop the last batch although it is smaller than 128\n",
        "test_data_loader = data.DataLoader(test_dataset, batch_size=128, shuffle=False,\n",
        "drop_last=False)\n",
        "\n",
        "def eval_model(model, data_loader):\n",
        "    model.eval() # Set model to eval mode\n",
        "    true_preds, num_preds = 0., 0.\n",
        "    \n",
        "    with torch.no_grad(): # Deactivate gradients for the following code\n",
        "        for data_inputs, data_labels in data_loader:\n",
        "            \n",
        "            # Determine prediction of model on dev set\n",
        "            data_inputs, data_labels = data_inputs.to(device), data_labels.to(device)\n",
        "            preds = model(data_inputs)\n",
        "            preds = preds.squeeze(dim=1)\n",
        "            preds = torch.max(preds) # Sigmoid to map predictions between 0 and 1\n",
        "            pred_labels = (preds >= 0.5).long() # Binarize predictions to 0 and 1\n",
        "            \n",
        "            # Keep records of predictions for the accuracy metric (true_preds=TP+TN, num_preds=TP+TN+FP+FN)\n",
        "            true_preds += (pred_labels == data_labels).sum()\n",
        "            num_preds += data_labels.shape[0]\n",
        "            \n",
        "    acc = true_preds / num_preds\n",
        "    print(f\"Accuracy of the model: {100.0*acc:4.2f}%\")\n",
        "    \n",
        "eval_model(model, test_data_loader)"
      ],
      "metadata": {
        "id": "O1PaCcnpmPsL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25fa730a-22cf-4163-e910-48387ca33c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model: 10.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import tensorboard logger from PyTorch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Load tensorboard extension for Jupyter Notebook, only need to start TB in the notebook\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "Llhw4Lfmn86D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"Training Code\"\n",
        "loss_module = nn.CrossEntropyLoss()\n",
        "# Input to the optimizer are the parameters of the model: model.parameters()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "data_loader = data.DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
        "# Push model to device. Has to be only done once\n",
        "model.to(device)\n",
        "\n",
        "def train_model(model, optimizer, data_loader, loss_module, num_epochs=20):\n",
        " # Set model to train mode\n",
        "    model.train()\n",
        "     # Training loop\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        for data_inputs, data_labels in data_loader:\n",
        "            ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
        "            data_inputs = data_inputs.to(device)\n",
        "            data_labels = data_labels.to(device)\n",
        "            ## Step 2: Run the model on the input data\n",
        "            preds = model(data_inputs)\n",
        "            preds = preds.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]\n",
        "            #Step 3: Calculate the loss\n",
        "            loss = loss_module(preds, data_labels)\n",
        "            ## Step 4: Perform backpropagation\n",
        "            # Before calculating the gradients, we need to ensure that they are all zero. \n",
        "            # The gradients would not be overwritten, but actually added to the existing ones.\n",
        "            optimizer.zero_grad() \n",
        "            # Perform backpropagation\n",
        "            loss.backward()\n",
        "            ## Step 5: Update the parameters\n",
        "            optimizer.step()\n",
        "\n",
        "#train_model(model, optimizer, data_loader, loss_module)"
      ],
      "metadata": {
        "id": "mAs98lnElrvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_with_logger(model, optimizer, data_loader, loss_module, val_dataset, num_epochs=100, logging_dir='runs/our_experiment'):\n",
        "    # Create TensorBoard logger\n",
        "    writer = SummaryWriter(logging_dir)\n",
        "    model_plotted = False\n",
        "    \n",
        "    # Set model to train mode\n",
        "    model.train() \n",
        "    \n",
        "    # Training loop\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        epoch_loss = 0.0\n",
        "        for data_inputs, data_labels in data_loader:\n",
        "            \n",
        "            ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
        "            data_inputs = data_inputs.to(device)\n",
        "            data_labels = data_labels.to(device)\n",
        "            \n",
        "            # For the very first batch, we visualize the computation graph in TensorBoard\n",
        "            if not model_plotted:\n",
        "                writer.add_graph(model, data_inputs)\n",
        "                model_plotted = True\n",
        "            \n",
        "            ## Step 2: Run the model on the input data\n",
        "            preds = model(data_inputs)\n",
        "            preds = preds.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]\n",
        "            \n",
        "            ## Step 3: Calculate the loss\n",
        "            loss = loss_module(preds, data_labels)\n",
        "            \n",
        "            ## Step 4: Perform backpropagation\n",
        "            # Before calculating the gradients, we need to ensure that they are all zero. \n",
        "            # The gradients would not be overwritten, but actually added to the existing ones.\n",
        "            optimizer.zero_grad() \n",
        "            # Perform backpropagation\n",
        "            loss.backward()\n",
        "            \n",
        "            ## Step 5: Update the parameters\n",
        "            optimizer.step()\n",
        "            \n",
        "            ## Step 6: Take the running average of the loss\n",
        "            epoch_loss += loss.item()\n",
        "            \n",
        "        # Add average loss to TensorBoard\n",
        "        epoch_loss /= len(data_loader)\n",
        "        writer.add_scalar('training_loss',\n",
        "                          epoch_loss,\n",
        "                          global_step = epoch + 1)\n",
        "        \n",
        "        # Visualize prediction and add figure to TensorBoard\n",
        "        # Since matplotlib figures can be slow in rendering, we only do it every 10th epoch\n",
        "        # if (epoch + 1) % 10 == 0:\n",
        "        #     fig = visualize_classification(model, val_dataset.data, val_dataset.label)\n",
        "        #     writer.add_figure('predictions',\n",
        "        #                       fig,\n",
        "        #                       global_step = epoch + 1)\n",
        "    \n",
        "    writer.close()"
      ],
      "metadata": {
        "id": "jwUGoYhSpSu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleClassifier().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "train_model_with_logger(model, optimizer, data_loader, loss_module, val_dataset=test_dataset)"
      ],
      "metadata": {
        "id": "Fx1XGN99pXme",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6183216a84074985986f6e0b71b5f131",
            "5be35566435c4c64a941ce6be3755bb3",
            "270defb485ec455dbc69a9e829b4d9a3",
            "55ecad4bbf234a1e8b0ef9d44c4fa0ff",
            "00d27fc799724d02a39eb24a2a9efa13",
            "b462cd2fb15b45a8a602faedd2108b3e",
            "fb64ae570ace4f75a51db88437bc01f0",
            "4f09e00b71474878be18b8255ee62e87",
            "d5ae9954bf0149d78dfa040571177ec3",
            "d618a1674aaa4ab093ba0d622f7f4deb",
            "06dcab0e488d465fb48032885cd8d3aa"
          ]
        },
        "outputId": "ef8c3119-3f22-49d6-d13f-1e578ce74ba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6183216a84074985986f6e0b71b5f131"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from warnings import simplefilter\n",
        "eval_model(model, data_loader)"
      ],
      "metadata": {
        "id": "vj_5APK2aeHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "j1EustMY6QXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 2b**\n",
        "\n",
        "Extend your CNN by adding one more additional convolution layer followed by an activation function and pooling function. You also need to adjust your fully connected layer properly with respect to intermediate feature dimensions. Train your network for 300 epochs. Report your training time, loss, and evaluation accuracy after 300 epochs. Analyze your results in your report and compare your model size and accuracy over the baseline implementation in Problem2.a. Do you see any over-fitting?"
      ],
      "metadata": {
        "id": "Mr0tbxFYSzVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = SimpleClassifier2().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "train_model_with_logger(model2, optimizer, data_loader, loss_module, val_dataset=test_dataset)"
      ],
      "metadata": {
        "id": "KvI-QR5uVezA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model(model2, data_loader)"
      ],
      "metadata": {
        "id": "X_mjI8WskyaR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}